{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    " #define folder paths for smaller images,for each class\n",
    "TUMOR_path = 'Kather_texture_2016_image_tiles_5000/01_TUMOR/'\n",
    "STROMA_path = 'Kather_texture_2016_image_tiles_5000/02_STROMA/'\n",
    "COMPLEX_path = 'Kather_texture_2016_image_tiles_5000/03_COMPLEX/'\n",
    "LYMPHO_path = 'Kather_texture_2016_image_tiles_5000/04_LYMPHO/'\n",
    "DEBRIS_path = 'Kather_texture_2016_image_tiles_5000/05_DEBRIS/'\n",
    "MUCOSA_path= 'Kather_texture_2016_image_tiles_5000/06_MUCOSA/'\n",
    "ADIPOSE_path = 'Kather_texture_2016_image_tiles_5000/07_ADIPOSE/'\n",
    "EMPTY_path = 'Kather_texture_2016_image_tiles_5000/08_EMPTY/'\n",
    "\n",
    "#Load the images from each folder path\n",
    "TUMOR = np.array([np.array(Image.open(TUMOR_path + fname)) for fname in os.listdir(TUMOR_path)])\n",
    "STROMA = np.array([np.array(Image.open(STROMA_path + fname)) for fname in os.listdir(STROMA_path)])\n",
    "COMPLEX = np.array([np.array(Image.open(COMPLEX_path + fname)) for fname in os.listdir(COMPLEX_path)])\n",
    "LYMPHO = np.array([np.array(Image.open(LYMPHO_path + fname)) for fname in os.listdir(LYMPHO_path)])\n",
    "DEBRIS = np.array([np.array(Image.open(DEBRIS_path + fname)) for fname in os.listdir(DEBRIS_path)])\n",
    "MUCOSA = np.array([np.array(Image.open(MUCOSA_path + fname)) for fname in os.listdir(MUCOSA_path)])\n",
    "ADIPOSE = np.array([np.array(Image.open(ADIPOSE_path + fname)) for fname in os.listdir(ADIPOSE_path)])\n",
    "EMPTY = np.array([np.array(Image.open(EMPTY_path + fname)) for fname in os.listdir(EMPTY_path)])\n",
    "\n",
    "#Create the labels for each image so we know which image belongs to which class\n",
    "TUMOR_labels = np.ones((len(TUMOR),1))\n",
    "STROMA_labels = np.ones((len(STROMA),1))*2\n",
    "COMPLEX_labels = np.ones((len(COMPLEX),1))*3\n",
    "LYMPHO_labels = np.ones((len(LYMPHO),1))*4\n",
    "DEBRIS_labels = np.ones((len(DEBRIS),1))*5\n",
    "MUCOSA_labels = np.ones((len(MUCOSA),1))*6\n",
    "ADIPOSE_labels = np.ones((len(ADIPOSE),1))*7\n",
    "EMPTY_labels = np.ones((len(EMPTY),1))*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all the images and labels into one X and y array\n",
    "X = np.concatenate((TUMOR,STROMA,COMPLEX,LYMPHO,DEBRIS,MUCOSA,ADIPOSE,EMPTY),axis=0)\n",
    "y = np.concatenate((TUMOR_labels,STROMA_labels,COMPLEX_labels,LYMPHO_labels,DEBRIS_labels,MUCOSA_labels,ADIPOSE_labels,EMPTY_labels),axis=0)\n",
    "\n",
    "#Shuffle the data (prevents non random assignment to training and testing)\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "#Split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#resize images to 50x50 and convert to grayscale as random forest classifier only accepts 2D data\n",
    "from skimage.transform import resize\n",
    "X_train = np.array([resize(image, (50, 50)) for image in X_train])\n",
    "X_test = np.array([resize(image, (50, 50)) for image in X_test])\n",
    "#Convert to grayscale\n",
    "X_train = np.array([np.mean(image, axis=2) for image in X_train])\n",
    "X_test = np.array([np.mean(image, axis=2) for image in X_test])\n",
    "\n",
    "#Normalize the data to be between 0 and 1 for same scale\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode the labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "#convert to 2D array for random forest classifier\n",
    "X_train = X_train.reshape(4000,2500)\n",
    "X_test = X_test.reshape(1000,2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14625 0.1225  0.12625 0.11    0.1075 ]\n"
     ]
    }
   ],
   "source": [
    "#perform the random forest classification using cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#define a basic classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "#perform the cross validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "#print the scores\n",
    "print(scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create gridsearch to find the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#create a dictionary of parameters to search\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'max_features': [2, 3],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "#instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = param_grid,\n",
    "                            cv = 5, n_jobs = -1, verbose = 2)                               \n",
    "#fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "#print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "#print the best score\n",
    "print(grid_search.best_score_)\n",
    "#save the best model\n",
    "best_grid = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
